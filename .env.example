# ==============================================================================
# LangGraph Learning - Environment Configuration
# ==============================================================================
# Copy this file to .env and fill in your values.
# Settings use PydanticSettings - see packages/shared/src/shared/settings.py
#
# Naming Convention:
# - Core settings: ENVIRONMENT, DEBUG, VERBOSE, LOG_LEVEL
# - Nested settings: GROUP__FIELD (e.g., LLM__OPENAI_API_KEY)
#
# Both flat and nested env vars are supported for backward compatibility:
# - OPENAI_API_KEY (flat, backward compat)
# - LLM__OPENAI_API_KEY (nested, preferred)

# ------------------------------------------------------------------------------
# Core Settings
# ------------------------------------------------------------------------------
# Application environment: development, staging, production
ENVIRONMENT=development

# Enable debug mode (true/false)
DEBUG=false

# Enable verbose output (true/false)
VERBOSE=false

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# ------------------------------------------------------------------------------
# LLM API Keys (nested: LLM__*)
# ------------------------------------------------------------------------------
# At least one LLM key is required for patterns that use language models.
# Keys are validated - placeholder values are automatically ignored.

# OpenAI API key for GPT models
# Nested: LLM__OPENAI_API_KEY (preferred)
# Flat: OPENAI_API_KEY (backward compat)
OPENAI_API_KEY=your-openai-key-here
# LLM__OPENAI_API_KEY=your-openai-key-here

# Anthropic API key for Claude models
# Nested: LLM__ANTHROPIC_API_KEY (preferred)
# Flat: ANTHROPIC_API_KEY (backward compat)
ANTHROPIC_API_KEY=your-anthropic-key-here
# LLM__ANTHROPIC_API_KEY=your-anthropic-key-here

# Google API key for Gemini models
# Nested: LLM__GOOGLE_API_KEY (preferred)
# Flat: GOOGLE_API_KEY (backward compat)
GOOGLE_API_KEY=your-google-key-here
# LLM__GOOGLE_API_KEY=your-google-key-here

# Default LLM provider: openai, anthropic, google
LLM__PROVIDER=openai

# Default model to use (gpt-4, gpt-4-turbo, claude-3-opus, etc.)
LLM__DEFAULT_MODEL=gpt-4

# ------------------------------------------------------------------------------
# LangSmith Tracing (nested: LANGSMITH__*)
# ------------------------------------------------------------------------------
# Enable tracing to LangSmith for debugging and monitoring.
# Cloud: https://smith.langchain.com (recommended for learning)
# Self-hosted: Requires Enterprise license
# Docs: https://docs.smith.langchain.com/

# Enable LangSmith tracing (true/false)
# When true, all LangChain/LangGraph operations are automatically traced
# Note: Legacy LANGCHAIN_TRACING_V2 is also supported for backward compatibility
LANGSMITH__TRACING_ENABLED=false

# LangSmith API key (from smith.langchain.com > Settings > API Keys)
# Note: Legacy LANGCHAIN_API_KEY is also supported for backward compatibility
LANGSMITH__API_KEY=your-langsmith-key-here

# LangSmith project name for organizing traces (creates automatically)
# Note: Legacy LANGCHAIN_PROJECT is also supported for backward compatibility
LANGSMITH__PROJECT=langgraph-learning

# ------------------------------------------------------------------------------
# LangSmith Advanced Settings (Optional)
# ------------------------------------------------------------------------------
# Custom endpoint for self-hosted LangSmith (Enterprise only)
# Default: https://api.smith.langchain.com
# LANGSMITH__ENDPOINT=http://localhost:1984

# Workspace ID for accounts with multiple workspaces
# LANGSMITH__WORKSPACE_ID=your-workspace-id

# Background tracing (default: true)
# Set to false for serverless environments (Lambda, Cloud Functions)
# LANGSMITH__TRACING_BACKGROUND=true
